{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613bd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cd287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_srt_file(srt_file_path):\n",
    "    with open(srt_file_path, 'r') as f:\n",
    "        srt_data = f.read()\n",
    "\n",
    "    srt_regex = r'(\\d+)\\n(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})\\n(.+?(?=\\n\\d|$))'\n",
    "\n",
    "    srt_matches = re.findall(srt_regex, srt_data, re.DOTALL)\n",
    "    srt_data_list = [(int(m[0]), m[1], m[2], m[3].replace('\\n', ' ')) for m in srt_matches]\n",
    "\n",
    "    return pd.DataFrame(srt_data_list, columns=['id', 'start_time', 'end_time', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7cffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3904\n",
      "   id    start_time      end_time               sentence\n",
      "0   1  00:00:25,108  00:00:27,610     (leaves rustling) \n",
      "1   2  00:00:27,610  00:00:29,279  Laura: ...years ago. \n",
      "2   3  00:00:29,279  00:00:32,615  (indistinct arguing) \n",
      "3   4  00:00:32,615  00:00:33,783       Max: That's it! \n",
      "4   5  00:00:33,783  00:00:36,077               â™ª â™ª \n"
     ]
    }
   ],
   "source": [
    "srt_file_path = 'd01_data\\english_subtitles.srt'\n",
    "df = parse_srt_file(srt_file_path)\n",
    "print(df.size)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f244b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_srt_file(srt_file_path, target_language):\n",
    "    df = parse_srt_file(srt_file_path)\n",
    "\n",
    "    # Initialize the translation pipeline\n",
    "    translator = pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-en-{target_language}\")\n",
    "\n",
    "    # Apply the translation pipeline to each sentence in the DataFrame\n",
    "    tqdm.pandas()\n",
    "    df['translated_sentence'] = df['sentence'].progress_apply(lambda x: translator(x, max_length=512)[0]['translation_text'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec18c268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\Documents\\MesProjets\\fr_subtitles_gen\\env\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 976/976 [11:49<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    start_time      end_time               sentence   \n",
      "0   1  00:00:25,108  00:00:27,610     (leaves rustling)   \\\n",
      "1   2  00:00:27,610  00:00:29,279  Laura: ...years ago.    \n",
      "2   3  00:00:29,279  00:00:32,615  (indistinct arguing)    \n",
      "3   4  00:00:32,615  00:00:33,783       Max: That's it!    \n",
      "4   5  00:00:33,783  00:00:36,077               â™ª â™ª    \n",
      "\n",
      "                                 translated_sentence  \n",
      "0                           (les feuilles rouillent)  \n",
      "1                                 Il y a des années.  \n",
      "2                        (argumentation indistincte)  \n",
      "3                                         C'est ça !  \n",
      "4  «A» et «A» de l'annexe I du règlement (UE) no ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "srt_file_path = 'd01_data\\english_subtitles.srt'\n",
    "target_language = 'fr' # Change this to the target language you want to translate to\n",
    "df = translate_srt_file(srt_file_path, target_language)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25951f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, tokenizer):\n",
    "    # Add start and end of sentence tokens and tokenize the input\n",
    "    sentence = f'>{sentence.strip()}'\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    # Translate the input and decode the output\n",
    "    outputs = model.generate(**inputs)\n",
    "    translated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39861036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_srt_file(srt_file_path, target_language):\n",
    "    df = parse_srt_file(srt_file_path)\n",
    "\n",
    "    # Initialize the MarianMT model and tokenizer\n",
    "    model_name = f'Helsinki-NLP/opus-mt-en-{target_language}'\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Apply the MarianMT model to each sentence in the DataFrame with a progress bar\n",
    "    tqdm.pandas()\n",
    "    df['translated_sentence'] = df['sentence'].progress_apply(lambda x: translate_sentence(x, model, tokenizer))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87418e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9d747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_srt_file(df, output_file_path):\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(str(row['id']) + '\\n')\n",
    "            f.write(row['start_time'] + ' --> ' + row['end_time'] + '\\n')\n",
    "            f.write(row['translated_sentence'] + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3f0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'd01_data/translated.srt'\n",
    "write_srt_file(df, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9156f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec02cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             (les feuilles rouillent)\n",
       "1                                   Il y a des années.\n",
       "2                          (argumentation indistincte)\n",
       "3                                           C'est ça !\n",
       "4    «A» et «A» de l'annexe I du règlement (UE) no ...\n",
       "5                                          (inaudible)\n",
       "6                                     Vous comprenez !\n",
       "7                                         Je le sais !\n",
       "8                                        Laura : Ohh !\n",
       "9                             (violon poignant jouant)\n",
       "Name: translated_sentence, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['translated_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19f7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
